# FCN(fully convolution network)ì— ê´€í•˜ì—¬


<aside>
ğŸ’¡ ì¶œì²˜: [https://wikidocs.net/147359](https://wikidocs.net/147359)

</aside>

> ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì¸ **CNNê¸°ë°˜ì˜ ëª¨ë¸(AlexNet, VGG16, GoogLeNet)ì„ semantic seg. task(ì—¬ëŸ¬ í´ë˜ìŠ¤ë¡œ í”½ì…€ ë¶„ë¥˜í•˜ëŠ” task)ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ë³€í˜•í•œ ëª¨ë¸**
> 

â†’ ì „ì´ í•™ìŠµìœ¼ë¡œ êµ¬í˜„í•¨

â†’ ì´í›„ ë‚˜ì˜¨ segmentation seg. taskë“¤ì€ ì£¼ë¡œ fcnì„ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§.

# **ì´ë¯¸ì§€ ë¶„ë¥˜(image classfication)**


ì´ë¯¸ì§€ ë‚´ì˜ ëª¨ë“  í”½ì…€ì—ì„œ í”¼ì³ ì¶”ì¶œí•˜ê³ ,

ì¶”ì¶œí•œ í”¼ì³ë“¤ì„ classifierì— ë„£ì–´ ì „ì²´(total) ì…ë ¥ ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡

# **ì´ë¯¸ì§€ ë¶„í• (Image seg.)**


**ì´ë¯¸ì§€ë¥¼ ì´ë£¨ëŠ” ëª¨ë“  í”½ì…€ë“¤ì˜ classë¥¼ ì˜ˆì¸¡í•˜ëŠ” task**ì„.

ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ì“°ì¸ pretain ë„¤íŠ¸ì›Œí¬ì—ì„œ feature extraction ë ˆì´ì–´ëŠ” ì¬í™œìš©í•˜ì—¬ featureë¥¼ ì¶”ì¶œí•˜ê³  fully connected layer(dense layer)ë¥¼ ë²„ë¦¬ê³  1*1 convì™€ up-scaling(transpose convolution)ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ (fine tuning) í”½ì…€ í´ë˜ìŠ¤ ë¶„ë¥˜ì˜ ì´ë¯¸ì§€ë‘ ê°™ì€ í¬ê¸°ë¥¼ ì•„ì›ƒí’‹ìœ¼ë¡œ í•˜ë„ë¡ í•¨.

![Untitled](/Deep%20Learning%20from%20Scratch/FCN/Untitled.png)

â†’ upscaling

# **Fully connected layer(FC layer) ì´ë€?(= dense layer)**


CNNì—ì„œ 	ë ˆì´ì–´ëŠ” í¬ê²Œ 2ê°€ì§€ ìœ í˜•ìœ¼ë¡œ ë‚˜ë‰œë‹¤.

- Convolution/pooling layer: ì´ë¯¸ì§€ë¥¼ (filter í†µí•´) ë¶„í• í•˜ê³  ë¶„ì„
- FC layer: ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ê³  ì„¤ëª…í•˜ëŠ” ë° ê°€ì¥ ì í•©í•˜ê²Œ ì˜ˆì¸¡ì„ í•˜ëŠ” ì¸µ

ì´ì¤‘ FC layerëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì—­í• ì„ í•œë‹¤.

- flattening: í‰íƒ„í™”, ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ í‰íƒ„í™”í•˜ì—¬ ë‹¤ìŒ ë ˆì´ì–´ì˜ ì…ë ¥ì´ ë  ìˆ˜ ìˆëŠ” ë‹¨ì¼ ë²¡í„°ë¡œ ë³€í™˜í•¨
- ë¨¼ì € ì…ë ¥ì„ ì·¨í•˜ì—¬ ë¼ë²¨ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ê³ , ê° ë¼ë²¨ì— ëŒ€í•œ ìµœì¢… í™•ë¥ ì„ ì œê³µí•¨.
- ì¦‰ convolution/pooling í”„ë¡œì„¸ìŠ¤ì˜ ê²°ê³¼ë¥¼ ì·¨í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¼ë²¨ë¡œ ë¶„ë¥˜í•˜ëŠ”ë° ì‚¬ìš©í•¨.(ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´)

# **ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°**


![Untitled](/Deep%20Learning%20from%20Scratch/FCN/Untitled%201.png)

1. Convolution layerë¡œ feature ì¶”ì¶œ
2. 1*1 convolution layerë¥¼ ì´ìš©í•˜ì—¬ feature mapì˜ ì±„ë„ìˆ˜ë¥¼ ë°ì´í„°ì…‹ì˜ ê°ì²´ìˆ˜(# of instance)ì™€ ë™ì¼í•˜ê²Œ ë³€ê²½ (class presence heat map ì¶”ì¶œ)
3. Up-sampling: ë‚®ì€ í•´ìƒë„ì˜ heat mapì„ upsampling(=transposed convolution) í•˜ê³ , ì…ë ¥ ì´ë¯¸ì§€ì™€ ê°™ì€ í¬ê¸°ì˜ map ìƒì„±
4. ìµœì¢… í”¼ì²˜ ë§µê³¼ ë¼ë²¨ í”¼ì²˜ë§µì˜ ì°¨ì´ë¥¼ ì´ìš©í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ

![Untitled](/Deep%20Learning%20from%20Scratch/FCN/Untitled%202.png)

ë§ˆì§€ë§‰ 7*7 í”¼ì²˜ ë§µì˜ í•œ í”½ì…€ì€ ê¸°ì¡´ ì¸í’‹ ì´ë¯¸ì§€ì˜ 32*32 pixelì„ ëŒ€í‘œí•˜ê²Œ ë˜ëŠ”ë°, ì´ë¥¼ ì—…ìƒ˜í”Œë§í•˜ëŠ” ê³¼ì •ì—ì„œ ê¸°ì¡´ ì´ë¯¸ì§€ì˜ ì •ë³´ê°€ ì†ì‹¤ë  ìˆ˜ ìˆë‹¤.(ë­‰ê·¸ëŸ¬ì§ ë¬¸ì œ) ë”°ë¼ì„œ ì—…ìƒ˜í”Œë§ì„ í•  ë•Œ í”¼ì²˜ ì¶”ì¶œ ë‹¨ê³„ì˜ í”¼ì²˜ë§µë„ ì—…ìƒ˜í”Œë§ì— í¬í•¨(sum)í•˜ì—¬ ì •ë³´ ì†ì‹¤ì„ ë§‰ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•¨.(**skip architecture, ì´ëŠ” íŒŒë¼ë¯¸í„°ì˜ í° ì¦ê°€ ì—†ì´ ì„±ëŠ¥ì„ ë¹„ì•½ì ìœ¼ë¡œ í–¥ìƒì‹œí‚´**)

ì–´ëŠ ë‹¨ê³„ì˜ í”¼ì²˜ì¶”ì¶œë‹¨ê³„ê¹Œì§€ë¥¼ ë°˜ì˜í•˜ëŠëƒì— ë”°ë¼ ì •í™•ë„ê°€ ë‹¬ë¼ì§„ë‹¤.(ì´ˆê¸°ì˜ í”¼ì²˜ì¶”ì¶œë‹¨ê³„ë¶€í„° ê³ ë ¤í• ìˆ˜ë¡ img. Seg. ì •í™•ë„ê°€ ë†’ì•„ì§„ë‹¤.)

![Untitled](/Deep%20Learning%20from%20Scratch/FCN/Untitled%203.png)

ì´ë¯¸ì§€ ë¶„í• ì„ í•˜ëŠ” fcnì€ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸°ì—, ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì´ ë°œë‹¬í• ìˆ˜ë¡, ì´ë¯¸ì§€ ë¶„í•  ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í–¥ìƒë¨.(ì´ë¯¸ì§€ ë¶„ë¥˜ ë„¤íŠ¸ì›Œí¬ì—ì„œ ì¶”ì¶œí•˜ëŠ” í”¼ì³ë¥¼ ì´ë¯¸ì§€ ë¶„í• ì—ì„œë„ ìˆ˜ì •ì—†ì´ ì‚¬ìš©ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸)

# **FC layerë¥¼ ì‚­ì œí•¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ ë¶„í• ì„ êµ¬í˜„í•¨**


FC layerë¥¼ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„í• ì„ í•˜ëŠ” ê²ƒì€ ì í•©í•˜ì§€ ì•ŠìŒ.

1. FC layerë¥¼ í†µê³¼í•˜ê³  ë‚˜ë©´ ì´ë¯¸ì§€ì˜ ìœ„ì¹˜ ì •ë³´ê°€ ì‚¬ë¼ì§€ê¸° ë•Œë¬¸
(ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ëŠ” ìœ„ì¹˜ì •ë³´ê°€ ì €ì¥ë˜ëŠ” ë°˜ë©´ FC layerëŠ” ìœ„ì¹˜ ì •ë³´ê°€ ì‚¬ë¼ì§)
2. FC layerëŠ” ê³ ì •ëœ í¬ê¸°ì˜ input imageë§Œ ë°›ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸
(Dense layerì— **ê°€ì¤‘ì¹˜ ê°œìˆ˜ê°€ ê³ ì •**ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ë°”ë¡œ ì• ë ˆì´ì–´ì˜ Feature Mapì˜ í¬ê¸°ë„ ê³ ì •ë¨
3. FC layerëŠ” íŒŒë¼ë¯¸í„° ê°œìˆ˜ë¥¼ ë„ˆë¬´ ë§ì´ í•„ìš”ë¡œ í•¨
(fully connected ì´ê¸° ë•Œë¬¸)

ì´ëŸ° ì´ìœ ë¡œ FC layerë¥¼ ì‚­ì œí•˜ê³  1*1 convolutionìœ¼ë¡œ ëŒ€ì²´í•¨.

# **FCNì—ì„œëŠ” deconvolutionì„ ì‚¬ìš©í•˜ëŠ”ê°€ ì•„ë‹˜ transposed convolutionì„ ì‚¬ìš©í•˜ëŠ”ê°€?**


ê°™ì€ ê°œë…ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½í–¥ì´ ìˆëŠ”ë“¯, convolutionì˜ ì—­ì—°ì‚°ì„ deconvolutionì´ë¼ê³  í•˜ëŠ”ë°, ê·¸ ì—­ì—°ì‚° ì•ˆì— transposed convolutionì´ í¬í•¨ë˜ëŠ” ë“¯

[https://gaussian37.github.io/vision-segmentation-fcn/](https://gaussian37.github.io/vision-segmentation-fcn/) fcn pytorchë¡œ êµ¬í˜„(í•œê¸€)

https://github.com/divamgupta/image-segmentation-keras â†’ fcn ê¸°ë°˜ ëª¨ë¸ë“¤ì„ êµ¬í˜„í•´ë†“ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬

[https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/fcn.py](https://github.com/divamgupta/image-segmentation-keras/blob/master/keras_segmentation/models/fcn.py) â†’ ìœ„ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ êµ¬í˜„í•œ fcn ëª¨ë¸ ì „ì²´ ì½”ë“œ

# í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë€?

ëª¨ë¸ì„ ì“¸ ë•Œ ì‚¬ìš©ìê°€ ì§ì ‘ ì„¤ì •í•˜ëŠ” ê°’(ìµœì ì˜ ê°’ì´ ì—†ìœ¼ë©° ê²½í—˜ ë²•ì¹™ìœ¼ë¡œ ê²°ì •ë˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.)ì´ë‹¤. ë°˜ë©´ íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ í˜¹ì€ ë°ì´í„°ì— ì˜í•´ ê²°ì •ëœë‹¤.

# **ì‚¬ìš©í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°/ ì† ëŒ€ë³¼ê³³**

[https://github.com/pytorch/vision/blob/bf843c664b8ba0ff49d2921237500c77d82f2d04/torchvision/models/segmentation/fcn.py#L9](https://github.com/pytorch/vision/blob/bf843c664b8ba0ff49d2921237500c77d82f2d04/torchvision/models/segmentation/fcn.py#L9) â†’ Fully Convolutional Networks for Semantic Seg.(CVPR 2015) ë…¼ë¬¸ FCN ëª¨ë¸ íŒŒì´ì¬ ì½”ë“œ

```python
from torch import nn

from ._utils import _SimpleSegmentationModel

__all__ = ["FCN"]

class FCN(_SimpleSegmentationModel):
    """
    Implements a Fully-Convolutional Network for semantic segmentation.

    Arguments:
        backbone (nn.Module): the network used to compute the features for the model.
            The backbone should return an OrderedDict[Tensor], with the key being
            "out" for the last feature map used, and "aux" if an auxiliary classifier
            is used.
        classifier (nn.Module): module that takes the "out" element returned from
            the backbone and returns a dense prediction.
        aux_classifier (nn.Module, optional): auxiliary classifier used during training
    """
    pass

class FCNHead(nn.Sequential):
    def __init__(self, in_channels, channels):
        inter_channels = in_channels // 4
        layers = [
            nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(inter_channels),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Conv2d(inter_channels, channels, 1)
        ]
# in_channels -(with filter size 3)-> in_channels//4 -(with_filter size 1)->1
# ->up-sampling
        super(FCNHead, self).__init__(*layers) #ë¶€ëª¨ í´ë˜ìŠ¤(nn.Sequential) í˜¸ì¶œ ë° ì´ˆê¸°í™”
```

- ì¸ì½”ë”ì™€ ë””ì½”ë” êµ¬ì¡°(ì–¼ë§ˆë‚˜ ë³µì¡í•˜ê²Œ ë§Œë“¤ê²ƒì¸ì§€, ë¬´ìŠ¨ ë°©ì‹ ì‚¬ìš©í•  ê²ƒì¸ì§€)
    - up-sampling ë°©ì•ˆ(ì¼ë°˜ì ìœ¼ë¡œëŠ” transpose convolutionì„ ì“°ëŠ” ë“¯)
    - CNN ê¸°ë°˜ ëª¨ë¸ ë­˜ ì±„íƒí• ì§€ (+CNNì˜ íŒŒë¼ë¯¸í„°ë“¤)
    - Skip architecture
- Data augmentation(ë°ì´í„°ì— ë”°ë¥¸ augmentation ë°©ì‹)
- ë¶„ë¥˜í•  í´ë˜ìŠ¤ ìˆ˜
- ì…ë ¥ ì´ë¯¸ì§€ í”½ì…€ í¬ê¸°
- batch normalization ë¹„ìœ¨
- ì´ë¯¸ì§€ í¬ë¡­ ì—¬ë¶€

<aside>
ğŸ’¡ ì•„ë§ˆ ì´ë²ˆ ì°½ì—…íŒ€ì—ì„œ ì°¾ìœ¼ë¼ëŠ” FCN ëª¨ë¸ì€ ì´ˆê¸° FCNëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë³€í˜•ëœ ê²ƒê¹Œì§€ í¬í•¨í•˜ëŠ” ê°œë…ìœ¼ë¡œ ë³´ì„. ì§ì ‘ í™œìš©ì„ í•˜ê¸° ìœ„í•œ ëª¨ë¸ì„ ì°¾ëŠ” ê²ƒì´ ì¤‘ìš”í•œë°, ë§Œì•½ ìš°ë¦¬ê°€ ì´ˆê¸° FCN ëª¨ë¸ë§Œ ì°¾ëŠ”ë‹¤ë©´ í™œìš© í•™ìŠµë³´ë‹¤ëŠ” ì´ë¡  í•™ìŠµì— ë” ê°€ê¹ê¸° ë•Œë¬¸.

</aside>

# ë‚´ê°€ ìƒê°í•˜ëŠ” FCNì˜ íŠ¹ì§• ì´ë€?

ê¸°ì¡´ CNN ëª¨ë¸ì— ë§ˆì§€ë§‰ dense ì¸µì„ ë¹¼ê³  1*1 ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ì™€ up-sampling êµ¬ì¡°ë¥¼ ë„£ì€ ê²ƒìœ¼ë¡œ ê¸°ì¡´ ì¸í’‹ê³¼ ê°™ì€ í¬ê¸°ì˜ ì•„ì›ƒí’‹ì„ ë‚´ë†“ëŠ”ë‹¤. ì£¼ë¡œ ì´ë¯¸ì§€ ë¶„í• ì— ì‚¬ìš©ëœë‹¤. 

<aside>
ğŸ’¡ í•˜ê³  ì‹¶ì€ ì§ˆë¬¸
1. ì§€ê¸ˆ í•˜ê³ ì í•˜ëŠ” taskê°€ image segmentationì¸ê°€, í˜¹ì€ instance segmentationì¸ê°€(ë¯¸ë˜ ë°©í–¥ì„±ì„ ì„¤ë¦½í•˜ëŠ”ë° ì¤‘ìš”í•œ ì§ˆë¬¸ì„.)

</aside>

# ì›ë³¸ ì´ë¯¸ì§€ì™€ Labelëœ ì´ë¯¸ì§€ ë°ì´í„°

[https://www.kaggle.com/code/vanvalkenberg/image-segmentation-u-net-for-self-driving-cars/data](https://www.kaggle.com/code/vanvalkenberg/image-segmentation-u-net-for-self-driving-cars/data) â†’ Cambridge labeled data

[https://www.kaggle.com/code/sgorl1234/image-segmentation-for-self-driving-cars/data](https://www.kaggle.com/code/sgorl1234/image-segmentation-for-self-driving-cars/data) â†’ì›ë³¸ê³¼ labelì´ í•©ì³ì ¸ ìˆìŒ(cityscapes_data)